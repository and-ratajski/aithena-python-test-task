"""LLM client protocol definitions.

This module defines the Protocol interfaces that all LLM client implementations must adhere to,
following the Dependency Inversion Principle from SOLID.
"""
from abc import abstractmethod
from typing import Any, Optional, Protocol, runtime_checkable


class LLMClientError(Exception):
    """Base exception for LLM client errors."""
    pass


@runtime_checkable
class LlmClient(Protocol):
    """Protocol defining the interface for all LLM clients.
    
    This Protocol follows the Dependency Inversion Principle, allowing high-level modules
    to depend on this abstraction rather than concrete implementations. All LLM client
    implementations (like Anthropic's Claude, OpenAI, etc.) must implement these methods.
    
    The Protocol enables:
    1. Easily swapping LLM providers without changing application code
    2. Testing with mock implementations
    3. Future extensibility to support new LLM providers
    """

    @abstractmethod
    def generate_response(
        self, 
        prompt: str, 
        system_prompt: Optional[str] = None,
        **kwargs: Any
    ) -> str:
        """Generate a text response from the LLM based on the provided prompt.
        
        This is the primary method for interacting with the LLM. It sends a user prompt
        and optional system prompt to the model and returns the generated text response.
        
        Args:
            prompt: The user message or question to send to the LLM
            system_prompt: Optional system prompt to set context or guide the model's behavior
            **kwargs: Additional provider-specific parameters to customize the request
            
        Returns:
            The generated text response from the LLM
            
        Raises:
            LLMClientError: If the API request fails
        """
        raise NotImplementedError()

    @abstractmethod
    def rewrite_to_rust(self, python_code: str) -> str:
        """Rewrite Python code to equivalent Rust code using the LLM.
        
        A specialized method that prompts the LLM to convert Python code to Rust.
        Implementations should format appropriate prompts with instructions for the model.
        
        Args:
            python_code: The Python code to convert to Rust
            
        Returns:
            Equivalent Rust code generated by the LLM
            
        Raises:
            LLMClientError: If the code conversion fails
        """
        raise NotImplementedError()